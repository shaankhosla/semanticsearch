{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uQAMl19YPbrH"
   },
   "outputs": [],
   "source": [
    "!pip3 install sentence_transformers\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "4rVid81PPgCI"
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "# Use Brown corpus\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"brown\")\n",
    "from nltk.corpus import brown\n",
    "\n",
    "sentences = [\" \".join(sent) for sent in brown.sents()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L-jWeq5JRGBa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading .gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 2.54MB/s]\n",
      "Downloading 1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.07MB/s]\n",
      "Downloading README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 42.6MB/s]\n",
      "Downloading config.json: 100%|██████████| 571/571 [00:00<00:00, 4.96MB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 983kB/s]\n",
      "Downloading data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 13.7MB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [00:08<00:00, 53.5MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 155kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 898kB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 6.25MB/s]\n",
      "Downloading tokenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 2.18MB/s]\n",
      "Downloading train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 14.5MB/s]\n",
      "Downloading vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 18.7MB/s]\n",
      "Downloading modules.json: 100%|██████████| 349/349 [00:00<00:00, 906kB/s]\n",
      "Batches:   1%|          | 16/1792 [00:14<21:00,  1.41it/s] "
     ]
    }
   ],
   "source": [
    "embedding_model = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "embeddings = embedding_model.encode(\n",
    "    sentences=sentences, convert_to_numpy=True, show_progress_bar=True\n",
    ")\n",
    "query_embedding, index_embeddings = embeddings[0], embeddings[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NlcPJW9SWyt"
   },
   "outputs": [],
   "source": [
    "print(query_embedding.shape, index_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cATWzvNcPeF6"
   },
   "outputs": [],
   "source": [
    "# Semantic search function\n",
    "def semantic_search(query_embedding, embeddings):\n",
    "    similarities = cosine_similarity([query_embedding], embeddings)\n",
    "    return np.argsort(-similarities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dLGNq9CPiXF"
   },
   "outputs": [],
   "source": [
    "embedding_sizes = list(range(25, query_embedding.shape[0], 25))\n",
    "times = []\n",
    "n_repeat = 500\n",
    "\n",
    "for size in embedding_sizes:\n",
    "    # Generate embeddings\n",
    "    query_embedding_reduced = query_embedding[:size]\n",
    "\n",
    "    # Reduce the dimension of the query embedding to match the current size\n",
    "    index_embeddings_reduced = index_embeddings[:, :size]\n",
    "\n",
    "    # Perform semantic search and measure time\n",
    "    start_time = time()\n",
    "    for i in range(n_repeat):\n",
    "        semantic_search(query_embedding_reduced, index_embeddings_reduced)\n",
    "    end_time = time()\n",
    "\n",
    "    time_taken = (end_time - start_time) / n_repeat\n",
    "    print(f\"Embedding Size: {size}, Time taken: {time_taken:.4f} seconds\\n\")\n",
    "    times.append(time_taken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_49QPPiTAe-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(embedding_sizes, times, marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "plt.title(\"Trade-off Between Embedding Size and Search Speed\")\n",
    "plt.xlabel(\"Embedding Size\")\n",
    "plt.ylabel(\"Time Taken (seconds)\")\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "# Display the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOcWZcHY3rQ2ejR72gCW2yg",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
