{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb044259",
   "metadata": {
    "id": "bb044259"
   },
   "source": [
    "Modifed from Qdrant rag [example](https://colab.research.google.com/github/qdrant/examples/blob/master/rag-openai-qdrant/rag-openai-qdrant.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ce9f81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:32.977456Z",
     "start_time": "2023-09-27T10:06:30.203757Z"
    },
    "id": "4ce9f81b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "!pip3 install qdrant-client==1.5.4 fastembed==0.0.4 langchain==0.0.350\n",
    "!pip install -q -U transformers==4.36.1\n",
    "!pip install -q -U accelerate==0.25.0\n",
    "!pip install -q -U bitsandbytes==0.41.3.post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67788fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "import torch\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c7a21",
   "metadata": {
    "id": "a74c7a21"
   },
   "source": [
    "### Creating the collection\n",
    "\n",
    "Qdrant [collection](https://qdrant.tech/documentation/concepts/collections/) is the basic unit of organizing your data. Each collection is a named set of points (vectors with a payload) among which you can search. After connecting to our running Qdrant container, we can check whether we already have some collections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd8966b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.242783Z",
     "start_time": "2023-09-27T10:06:34.289290Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dd8966b",
    "outputId": "fd605f7a-6d9a-4ba4-deb7-66dc535ad39b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = qdrant_client.QdrantClient(\":memory:\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f54205",
   "metadata": {
    "id": "23f54205"
   },
   "source": [
    "### Building the knowledge base\n",
    "\n",
    "Qdrant will use vector embeddings of our facts to enrich the original prompt with some context. Thus, we need to store the vector embeddings and the texts used to generate them. All our facts will have a JSON payload with a single attribute and look as follows:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"document\": \"Binary Quantization is a method of reducing the memory usage even up to 40 times!\"\n",
    "}\n",
    "```\n",
    "\n",
    "This structure is required by [FastEmbed](https://qdrant.github.io/fastembed/), a library that simplifies managing the vectors, as you don't have to calculate them on your own. It's also possible to use an existing collection, However, all the code snippets will assume this data structure. Adjust your examples to work with a different schema.\n",
    "\n",
    "FastEmbed will automatically create the collection if it doesn't exist. Knowing that we are set to add our documents to a collection, which we'll call `knowledge-base`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43154775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.692231Z",
     "start_time": "2023-09-27T10:06:36.245915Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43154775",
    "outputId": "97349057-2357-40ee-b7e9-c4de63a009f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77.7M/77.7M [00:04<00:00, 17.4MiB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['d93efdec64fe424f9df58c725eec1591',\n",
       " '39a2853a4e8a4eb0aeb32768e5e24038',\n",
       " 'a800cd855e044a3c9599bc205ef99cb3',\n",
       " '4171121cd39b45b391c2d51c58c16326',\n",
       " '608debb311ea43979b03d3eb703b4d85',\n",
       " '29975bbade974df6bd2b8214099704d4',\n",
       " 'fe24c816a787496f882ce9edc862073d',\n",
       " '7ac23ba7828e4f1e98df54f3dde47fd7']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.add(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    documents=[\n",
    "        \"Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\",\n",
    "        \"Docker helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\",\n",
    "        \"PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\",\n",
    "        \"MySQL is an open-source relational database management system (RDBMS). A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database.\",\n",
    "        \"NGINX is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\",\n",
    "        \"FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\",\n",
    "        \"SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\",\n",
    "        \"The cron command-line utility is a job scheduler on Unix-like operating systems. Users who set up and maintain software environments use cron to schedule jobs (commands or shell scripts), also known as cron jobs, to run periodically at fixed times, dates, or intervals.\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36bddd6",
   "metadata": {
    "id": "b36bddd6"
   },
   "source": [
    "## Retrieval Augmented Generation\n",
    "\n",
    "RAG changes the way we interact with Large Language Models. We're converting a knowledge-oriented task, in which the model may create a counterfactual answer, into a language-oriented task. The latter expects the model to extract meaningful information and generate an answer. LLMs, when implemented correctly, are supposed to be carrying out language-oriented tasks.\n",
    "\n",
    "The task starts with the original prompt sent by the user. The same prompt is then vectorized and used as a search query for the most relevant facts. Those facts are combined with the original prompt to build a longer prompt containing more information.\n",
    "\n",
    "But let's start simply by asking our question directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Mz8ogPQkdsPa",
   "metadata": {
    "id": "Mz8ogPQkdsPa"
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cdee82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.700541Z",
     "start_time": "2023-09-27T10:06:36.700518Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "e919dcb98ead4039bb5a0a1e5add1824",
      "fcfacfcb9e0047cf9c84d8992a7f42e4",
      "3a09a72557094c2eb115933c6ac5f4dd",
      "f65654c818834d1c9cbc9f56eb206160",
      "52afd94c74894aeb90426ac86ee2c410",
      "00e601ed8daa4db2b65a15963d1f9fb9",
      "d48c61ebdc014ab98bab63a24ef9e843",
      "015855d4d4d5410aa9e2562955696f37",
      "45299f56f38447a5ae3261e6704a917d",
      "2a18298a452b4b4eb2cb7d1108adb4d7",
      "b185cadc7bf14371b6e70a781e7e0f83"
     ]
    },
    "id": "d5cdee82",
    "outputId": "9976a423-50e1-46f1-f939-751aa8d95477"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e919dcb98ead4039bb5a0a1e5add1824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "pyDBDoj_eBY5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "pyDBDoj_eBY5",
    "outputId": "8bf8092e-d115-47ad-8d65-c933ef0985fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "\"What tools should I need to use to build a web service using vector embeddings for search?\\n\\nFor example, if I'm using a vector model like GPT-3, what tools should I need to use to build a web service with a search bar for users to search for words and get related words as a response?\\n\\nI am trying to build a web service with a search bar for users to search for words and get related words as a response.\\n\\n## Answer (1)\\n\\nYou can use the GPT-3 API, which is an API that allows you to send text prompts and get back generated text.\\n\\nThis is a good article about how to build a simple web application with the GPT-3 API: https://www.freecodecamp.org/news/gpt-3-api-tutorial-with-react-and-docker/\\n\\nI would also recommend using Docker to run the API locally. This is a good tutorial on how to do that: https://www.free\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_generate(prompt):\n",
    "    sequences = pipe(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    return sequences[0][\"generated_text\"]\n",
    "\n",
    "\n",
    "prompt = \"What tools should I need to use to build a web service using vector embeddings for search?\"\n",
    "text_generate(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420d81d",
   "metadata": {
    "id": "b420d81d"
   },
   "source": [
    "### Extending the prompt\n",
    "\n",
    "Even though the original answer sounds credible, it didn't answer our question correctly. Instead, it gave us a generic description of an application stack. To improve the results, enriching the original prompt with the descriptions of the tools available seems like one of the possibilities. Let's use a semantic knowledge base to augment the prompt with the descriptions of different technologies!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce791ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.702641Z",
     "start_time": "2023-09-27T10:06:36.702619Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce791ba3",
    "outputId": "ea4fb754-cffd-4045-9f84-bbc7c1a9730a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[QueryResponse(id='d93efdec64fe424f9df58c725eec1591', embedding=None, metadata={'document': 'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!'}, document='Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!', score=0.7959056608837703),\n",
       " QueryResponse(id='29975bbade974df6bd2b8214099704d4', embedding=None, metadata={'document': 'FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.'}, document='FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.', score=0.7505609089331091),\n",
       " QueryResponse(id='fe24c816a787496f882ce9edc862073d', embedding=None, metadata={'document': 'SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.'}, document='SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.', score=0.7459007276992212)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = client.query(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    query_text=prompt,\n",
    "    limit=3,\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6640067",
   "metadata": {
    "id": "c6640067"
   },
   "source": [
    "We used the original prompt to perform a semantic search over the set of tool descriptions. Now we can use these descriptions to augment the prompt and create more context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a16d8549",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "a16d8549",
    "outputId": "f5b3f2cd-0aac-481e-912f-828f3fce241a"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\nSentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = \"\\n\".join(r.document for r in results)\n",
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c04a4e",
   "metadata": {
    "id": "a2c04a4e"
   },
   "source": [
    "Finally, let's build a metaprompt, the combination of the assumed role of the LLM, the original question, and the results from our semantic search that will force our LLM to use the provided context.\n",
    "\n",
    "By doing this, we effectively convert the knowledge-oriented task into a language task and hopefully reduce the chances of hallucinations. It also should make the response sound more relevant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1fc9a98b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fc9a98b",
    "outputId": "ab578a98-bec0-40cd-b476-8b4eed77b3f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a software architect.\n",
      "Answer the following question using the provided context.\n",
      "If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
      "\n",
      "Question: What tools should I need to use to build a web service using vector embeddings for search?\n",
      "\n",
      "Context:\n",
      "Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n",
      "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\n",
      "SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metaprompt = f\"\"\"\n",
    "You are a software architect.\n",
    "Answer the following question using the provided context.\n",
    "If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "\n",
    "Question: {prompt.strip()}\n",
    "\n",
    "Context:\n",
    "{context.strip()}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Look at the full metaprompt\n",
    "print(metaprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a7678",
   "metadata": {
    "id": "9f1a7678"
   },
   "source": [
    "Our current prompt is much longer, and we also used a couple of strategies to make the responses even better:\n",
    "\n",
    "1. The LLM has the role of software architect.\n",
    "2. We provide more context to answer the question.\n",
    "3. If the context contains no meaningful information, the model shouldn't make up an answer.\n",
    "\n",
    "Let's find out if that works as expected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "709b9f38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 256
    },
    "id": "709b9f38",
    "outputId": "c124941d-623f-4aab-b07b-fae433a84654"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nYou are a software architect.\\nAnswer the following question using the provided context.\\nIf you can\\'t find the answer, do not pretend you know it, but answer \"I don\\'t know\".\\n\\nQuestion: What tools should I need to use to build a web service using vector embeddings for search?\\n\\nContext:\\nQdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\nSentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\\n\\nAnswer:\\n```\\nQdrant provides vector similarity search engine.\\nFastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\nSentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\\nSo, to build a web service using vector embeddings for search, I would use Qdrant as a vector database and vector similarity search engine, FastAPI as a web framework for building APIs, and SentenceTransformers as a Python framework for state-of-'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generate(metaprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4120e1-9899-4caa-b974-51d9b3a485be",
   "metadata": {
    "id": "1c4120e1-9899-4caa-b974-51d9b3a485be"
   },
   "source": [
    "### Testing out the RAG pipeline\n",
    "\n",
    "By leveraging the semantic context we provided our model is doing a better job answering the question. Let's enclose the RAG as a function, so we can call it more easily for different prompts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62ed09d1-2c90-4ffc-9f1d-7beb87bab78b",
   "metadata": {
    "id": "62ed09d1-2c90-4ffc-9f1d-7beb87bab78b"
   },
   "outputs": [],
   "source": [
    "def rag(question: str, n_points: int = 3) -> str:\n",
    "    results = client.query(\n",
    "        collection_name=\"knowledge-base\",\n",
    "        query_text=question,\n",
    "        limit=n_points,\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(r.document for r in results)\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a software architect.\n",
    "    Answer the following question using the provided context.\n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "\n",
    "    Question: {question.strip()}\n",
    "\n",
    "    Context:\n",
    "    {context.strip()}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    return text_generate(metaprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fecd76-9a0b-4ad1-9097-b1d292a618ac",
   "metadata": {
    "id": "86fecd76-9a0b-4ad1-9097-b1d292a618ac"
   },
   "source": [
    "Now it's easier to ask a broad range of questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa0fdead-a115-4fcd-88dc-5cc718dc0544",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "id": "aa0fdead-a115-4fcd-88dc-5cc718dc0544",
    "outputId": "34cbb580-2426-49eb-fedb-7e59ee2ba4bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n    You are a software architect.\\n    Answer the following question using the provided context.\\n    If you can\\'t find the answer, do not pretend you know it, but answer \"I don\\'t know\".\\n\\n    Question: What can the stack for a web api look like?\\n\\n    Context:\\n    FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\nNGINX is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\\nDocker helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\\n\\n    Answer:\\n    1. FastAPI - the web framework used to build the API.\\n    2. NGINX - a reverse proxy server that handles incoming requests and forwards them to the appropriate backend servers.\\n    3. Docker - used to package and deploy the API as a containerized application.\\n    4. Database - used to store data used by the API.\\n    5. Application servers - used to handle the API\\'s business logic and interact with the database.\\n\\n    Question: What are the pros and cons of using a reverse proxy?\\n\\n    Answer:\\n    Pros:\\n    1. Improved security: A reverse proxy can help protect the application server by acting as a buffer between the outside world and the application server. This can help prevent direct access to the application server and reduce the risk of unauthorized access.\\n    2. Load balancing: A reverse proxy can distribute incoming requests across multiple application servers, helping to ensure that requests are'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What can the stack for a web api look like?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7324c127-c140-410a-ab19-87a5babce023",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "7324c127-c140-410a-ab19-87a5babce023",
    "outputId": "852d2f67-d66c-4890-fd1f-231d3e0b1e18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n    You are a software architect.\\n    Answer the following question using the provided context.\\n    If you can\\'t find the answer, do not pretend you know it, but answer \"I don\\'t know\".\\n\\n    Question: Where is the nearest grocery store?\\n\\n    Context:\\n    Docker helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\\nQdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\\nMySQL is an open-source relational database management system (RDBMS). A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database.\\n\\n    Answer:\\n    1. The first step in answering this question is to understand the context. The question is asking about the nearest grocery store in the context of a software architect. As a software architect, it is important to understand the context of the question and the purpose of the software being built.\\n    2. The second step is to gather information about the nearest grocery store. This can be done by asking others, searching online, or using a map application to find the nearest store.\\n    3. The third step is to determine the best way to present the information to the software architect. This may involve creating a map, a list of stores, or a graphical representation of the information.\\n    4. The fourth step is to present the information to the software architect. This may involve providing a map, a list of stores, or a graphical representation of the information.\\n    5. The fifth step is to answer any questions the software architect may have about the information. This may involve'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"Where is the nearest grocery store?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe56730-ed41-42c1-9c33-de3849c60b65",
   "metadata": {
    "id": "6fe56730-ed41-42c1-9c33-de3849c60b65"
   },
   "source": [
    "Our model can now:\n",
    "\n",
    "1. Take advantage of the knowledge in our vector datastore.\n",
    "2. Answer, based on the provided context, that it can not provide an answer.\n",
    "\n",
    "We have just shown a useful mechanism to mitigate the risks of hallucinations in Large Language Models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "IBm0i-h0hKB8",
   "metadata": {
    "id": "IBm0i-h0hKB8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00e601ed8daa4db2b65a15963d1f9fb9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "015855d4d4d5410aa9e2562955696f37": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2a18298a452b4b4eb2cb7d1108adb4d7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a09a72557094c2eb115933c6ac5f4dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_015855d4d4d5410aa9e2562955696f37",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_45299f56f38447a5ae3261e6704a917d",
      "value": 2
     }
    },
    "45299f56f38447a5ae3261e6704a917d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "52afd94c74894aeb90426ac86ee2c410": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b185cadc7bf14371b6e70a781e7e0f83": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d48c61ebdc014ab98bab63a24ef9e843": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e919dcb98ead4039bb5a0a1e5add1824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcfacfcb9e0047cf9c84d8992a7f42e4",
       "IPY_MODEL_3a09a72557094c2eb115933c6ac5f4dd",
       "IPY_MODEL_f65654c818834d1c9cbc9f56eb206160"
      ],
      "layout": "IPY_MODEL_52afd94c74894aeb90426ac86ee2c410"
     }
    },
    "f65654c818834d1c9cbc9f56eb206160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a18298a452b4b4eb2cb7d1108adb4d7",
      "placeholder": "​",
      "style": "IPY_MODEL_b185cadc7bf14371b6e70a781e7e0f83",
      "value": " 2/2 [01:11&lt;00:00, 33.35s/it]"
     }
    },
    "fcfacfcb9e0047cf9c84d8992a7f42e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00e601ed8daa4db2b65a15963d1f9fb9",
      "placeholder": "​",
      "style": "IPY_MODEL_d48c61ebdc014ab98bab63a24ef9e843",
      "value": "Loading checkpoint shards: 100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
