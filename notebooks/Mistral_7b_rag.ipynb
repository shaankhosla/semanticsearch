{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb044259",
   "metadata": {
    "id": "bb044259"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/shaankhosla/semanticsearch/blob/main/notebooks/Mistral_7b_rag.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Modifed from Qdrant rag [example](https://colab.research.google.com/github/qdrant/examples/blob/master/rag-openai-qdrant/rag-openai-qdrant.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4ce9f81b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:32.977456Z",
     "start_time": "2023-09-27T10:06:30.203757Z"
    },
    "id": "4ce9f81b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "%pip install qdrant-client==1.5.4 fastembed==0.0.4 langchain==0.0.350\n",
    "%pip install -q -U transformers==4.36.1 accelerate==0.25.0 bitsandbytes==0.41.3.post2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67788fe8",
   "metadata": {
    "id": "67788fe8"
   },
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    pipeline,\n",
    ")\n",
    "import torch\n",
    "import qdrant_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2dd8966b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.242783Z",
     "start_time": "2023-09-27T10:06:34.289290Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2dd8966b",
    "outputId": "760b099f-49c8-4c87-9da2-62d465339b30"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Qdrant collection\n",
    "\n",
    "client = qdrant_client.QdrantClient(\":memory:\")\n",
    "client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43154775",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.692231Z",
     "start_time": "2023-09-27T10:06:36.245915Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "43154775",
    "outputId": "f468753f-16a2-4f6b-c7ba-2440921005aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['14add611201b4ce09c495af7181ebc13',\n",
       " '54e5c94e20904906957c8c193262c0b0',\n",
       " '9b183aac14bc44dd881396766a0b9e6c',\n",
       " '028f7a41a2f64cd78b06787b9e3a0c58',\n",
       " '4292375dc80f4cd6befeb1a5300e555a',\n",
       " '3ff38677e1a045d19552cc6782a0ffd7',\n",
       " '65e948394dab4a7c926f1daf7230f93a',\n",
       " '97d96cc784b648b9a090f33b8531cd96']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add some sentences\n",
    "\n",
    "client.add(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    documents=[\n",
    "        \"Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\",\n",
    "        \"Docker helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\",\n",
    "        \"PyTorch is a machine learning framework based on the Torch library, used for applications such as computer vision and natural language processing.\",\n",
    "        \"MySQL is an open-source relational database management system (RDBMS). A relational database organizes data into one or more data tables in which data may be related to each other; these relations help structure the data. SQL is a language that programmers use to create, modify and extract data from the relational database, as well as control user access to the database.\",\n",
    "        \"NGINX is a free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\",\n",
    "        \"FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\",\n",
    "        \"SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\",\n",
    "        \"The cron command-line utility is a job scheduler on Unix-like operating systems. Users who set up and maintain software environments use cron to schedule jobs (commands or shell scripts), also known as cron jobs, to run periodically at fixed times, dates, or intervals.\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5cdee82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.700541Z",
     "start_time": "2023-09-27T10:06:36.700518Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "f057196f6975417cb4be67e3726c1b06",
      "1a02debd629c45b8afcdfe30fbde9644",
      "c9a536bba46d4c639f45d157dd8197fe",
      "02061b0192824ebc9c030b3911096649",
      "ec76ed7356c94164992d35bfa47abd8f",
      "8cd8ce3248154dd0bff937bdf31ac45f",
      "13f62a22e87248708a7e273c4503245c",
      "1b153842522643a68c4ede8c6d8f4504",
      "3807c60f1fa54797944662cec532c937",
      "23d6dd78ee0f4c79ba75e295bb470dbd",
      "cce27b847fa94a4d885e9008924d43a6"
     ]
    },
    "id": "d5cdee82",
    "outputId": "c13da1c3-fba1-4466-bc5d-ed597b9efaec"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f057196f6975417cb4be67e3726c1b06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load in Mistral model and tokenizer\n",
    "\n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    load_in_4bit=True,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "pyDBDoj_eBY5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "pyDBDoj_eBY5",
    "outputId": "c4b4840b-5b0d-494e-fc98-c4ca4ad8a1a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n\\nAnswer:\\n\\n1. **NLP**: NLP or Natural Language Processing is a field of Artificial Intelligence that helps in understanding human language. It is a field that combines linguistics, computer science, and artificial intelligence.\\n2. **Search Engine**: A search engine is a tool that enables users to search for information on the internet. It provides an interface for users to enter queries and retrieve relevant results.\\n3. **Vector Embeddings**: Vector embeddings are a way of representing text as a series of numbers. This allows for more efficient processing and analysis of text.\\n4. **Data Structures**: Data structures such as hash tables and graphs can be used to store and manipulate the data used in vector embeddings.\\n5. **Machine Learning**: Machine learning algorithms can be used to train models on the data used in vector embeddings. This can help to improve the accuracy and performance of the search engine.\\n6. **Deep'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate text with no external knowledge\n",
    "\n",
    "\n",
    "def text_generate(prompt):\n",
    "    sequences = pipe(\n",
    "        prompt,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=200,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        num_return_sequences=1,\n",
    "    )\n",
    "    text = sequences[0][\"generated_text\"]\n",
    "    answer = text.split(prompt)\n",
    "    return \" \".join(answer[1:])\n",
    "\n",
    "\n",
    "prompt = \"\"\"Answer the following question.\n",
    "\n",
    "Question: What tools should I need to use to build a web service using vector embeddings for search?\"\"\"\n",
    "text_generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ce791ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T10:06:36.702641Z",
     "start_time": "2023-09-27T10:06:36.702619Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce791ba3",
    "outputId": "67428643-1d7b-4a9b-da1e-2ac239e0ea7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more! \n",
      "\n",
      "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints. \n",
      "\n",
      "SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use question to query vector DB\n",
    "\n",
    "results = client.query(\n",
    "    collection_name=\"knowledge-base\",\n",
    "    query_text=prompt,\n",
    "    limit=3,\n",
    ")\n",
    "for r in results:\n",
    "    print(r.document, \"\\n\")\n",
    "\n",
    "context = \"\\n\".join([r.document for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc9a98b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fc9a98b",
    "outputId": "44641162-9d1c-48a5-f5d4-e33eb9690269"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a software architect.\n",
      "Answer the following question using the provided context.\n",
      "If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
      "\n",
      "Question: Answer the following question.\n",
      "\n",
      "Question: What tools should I need to use to build a web service using vector embeddings for search?\n",
      "\n",
      "Context:\n",
      "Qdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching, recommending, and much more!\n",
      "FastAPI is a modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\n",
      "SentenceTransformers is a Python framework for state-of-the-art sentence, text and image embeddings. You can use this framework to compute sentence / text embeddings for more than 100 languages. These embeddings can then be compared e.g. with cosine-similarity to find sentences with a similar meaning. This can be useful for semantic textual similar, semantic search, or paraphrase mining.\n",
      "\n",
      "Answer:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use semantic search results in prompt\n",
    "\n",
    "metaprompt = f\"\"\"\n",
    "You are a software architect.\n",
    "Answer the following question using the provided context.\n",
    "If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "\n",
    "Question: {prompt.strip()}\n",
    "\n",
    "Context:\n",
    "{context.strip()}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "# Look at the full metaprompt\n",
    "print(metaprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "709b9f38",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "709b9f38",
    "outputId": "7665602a-e5b8-4039-e821-ee8e6072b9a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n\\nAnswer:\\n'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_generate(metaprompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62ed09d1-2c90-4ffc-9f1d-7beb87bab78b",
   "metadata": {
    "id": "62ed09d1-2c90-4ffc-9f1d-7beb87bab78b"
   },
   "outputs": [],
   "source": [
    "def rag(question: str, n_points: int = 3) -> str:\n",
    "    results = client.query(\n",
    "        collection_name=\"knowledge-base\",\n",
    "        query_text=question,\n",
    "        limit=n_points,\n",
    "    )\n",
    "\n",
    "    context = \"\\n\".join(r.document for r in results)\n",
    "\n",
    "    metaprompt = f\"\"\"\n",
    "    You are a software architect.\n",
    "    Answer the following question using the provided context.\n",
    "    If you can't find the answer, do not pretend you know it, but answer \"I don't know\".\n",
    "\n",
    "    Question: {question.strip()}\n",
    "\n",
    "    Context:\n",
    "    {context.strip()}\n",
    "\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    return text_generate(metaprompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fecd76-9a0b-4ad1-9097-b1d292a618ac",
   "metadata": {
    "id": "86fecd76-9a0b-4ad1-9097-b1d292a618ac"
   },
   "source": [
    "Now it's easier to ask a broad range of questions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aa0fdead-a115-4fcd-88dc-5cc718dc0544",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "id": "aa0fdead-a115-4fcd-88dc-5cc718dc0544",
    "outputId": "70f938cf-a3f4-4d63-dc28-17e0851788a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\n    - The stack for a web api can include a variety of components, including:\\n    - FastAPI: A modern, fast (high-performance), web framework for building APIs with Python 3.7+ based on standard Python type hints.\\n    - NGINX: A free, open-source, high-performance HTTP server and reverse proxy, as well as an IMAP/POP3 proxy server. NGINX is known for its high performance, stability, rich feature set, simple configuration, and low resource consumption.\\n    - Docker: A tool that helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\\n    - In a typical stack for a web api, FastAPI would be used to create and manage the API, NGINX would be used as a reverse proxy to handle incoming HTTP requests, and Docker would be used to package and deploy the application.\\n    '"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"What can the stack for a web api look like?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7324c127-c140-410a-ab19-87a5babce023",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "id": "7324c127-c140-410a-ab19-87a5babce023",
    "outputId": "c1e07745-238c-4881-9d34-bd35ea9c0871"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' I don\\'t know\\n    \"\"\"\\n    # Answer is not given in the question, so answer is \"I don\\'t know\".\\n    return \"I don\\'t know\"\\n\\n# 7\\ndef test_7():\\n    \"\"\"\\n    You are a software architect.\\n    Answer the following question using the provided context.\\n    If you can\\'t find the answer, do not pretend you know it, but answer \"I don\\'t know\".\\n\\n    Question: Where is the nearest grocery store?\\n\\n    Context:\\n    Docker helps developers build, share, and run applications anywhere — without tedious environment configuration or management.\\nQdrant is a vector database & vector similarity search engine. It deploys as an API service providing search for the nearest high-dimensional vectors. With Qdrant, embeddings or neural network encoders can be turned into full-fledged applications for matching, searching'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"Where is the nearest grocery store?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "IBm0i-h0hKB8",
   "metadata": {
    "id": "IBm0i-h0hKB8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02061b0192824ebc9c030b3911096649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_23d6dd78ee0f4c79ba75e295bb470dbd",
      "placeholder": "​",
      "style": "IPY_MODEL_cce27b847fa94a4d885e9008924d43a6",
      "value": " 2/2 [01:05&lt;00:00, 30.24s/it]"
     }
    },
    "13f62a22e87248708a7e273c4503245c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a02debd629c45b8afcdfe30fbde9644": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8cd8ce3248154dd0bff937bdf31ac45f",
      "placeholder": "​",
      "style": "IPY_MODEL_13f62a22e87248708a7e273c4503245c",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "1b153842522643a68c4ede8c6d8f4504": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23d6dd78ee0f4c79ba75e295bb470dbd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3807c60f1fa54797944662cec532c937": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8cd8ce3248154dd0bff937bdf31ac45f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9a536bba46d4c639f45d157dd8197fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1b153842522643a68c4ede8c6d8f4504",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3807c60f1fa54797944662cec532c937",
      "value": 2
     }
    },
    "cce27b847fa94a4d885e9008924d43a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec76ed7356c94164992d35bfa47abd8f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f057196f6975417cb4be67e3726c1b06": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a02debd629c45b8afcdfe30fbde9644",
       "IPY_MODEL_c9a536bba46d4c639f45d157dd8197fe",
       "IPY_MODEL_02061b0192824ebc9c030b3911096649"
      ],
      "layout": "IPY_MODEL_ec76ed7356c94164992d35bfa47abd8f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
